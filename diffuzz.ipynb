{"cells":[{"cell_type":"markdown","source":["# Diffusion process"],"metadata":{"id":"4L52WbQF0Crj"}},{"cell_type":"markdown","source":["<img src='https://drive.google.com/uc?id=1aMLLAiDU4d_2C77asMCYHpwOkz1jrc__' width=\"1000\"/>"],"metadata":{"id":"DQ1p4lfOuSiI"}},{"cell_type":"markdown","source":["## Forward diffusion process\n","The forward diffusion process is a Markovian process that iteratively adds Gaussian noise to a data point over ùëá iterations. Each step in the forward direction is given by"],"metadata":{"id":"3iUAOk58K9hC"}},{"cell_type":"markdown","source":["$$\n","q(x_t | x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t} x_{t-1}, \\beta_tI)\n","$$\n","\n","where $\\beta_t$ is a Gaussian noise with variance at timestep $t$\n","\n","At each timestep $ t $, the parameters that define the distribution of image $x_t$ are set as:\n","   - Mean: $\\sqrt{1 - \\beta_t} x_{t-1}$\n","   - Covariance: $( \\beta_t I )$\n","\n"],"metadata":{"id":"GYsanPZ_LEhg"}},{"cell_type":"markdown","source":["Given raw data $x_0$, sampling of $x_t$ is expressed as a single step in a closed form:\n"],"metadata":{"id":"aJMoTHqpLEno"}},{"cell_type":"markdown","source":["$$\n","q(x_t | x_0) = \\mathcal{N}(x_t; \\sqrt{\\hat{\\alpha}_t} x_0, (1 - \\hat{\\alpha}_t))\n","$$\n","where $\\alpha_t = 1 - \\beta_t$ and $\\hat{\\alpha}_t = \\prod_{s=1}^t (1 - \\beta_s)$. Therefore, $x_t$ can be expressed as a linear combination of $x_0$ and $\\epsilon$ using the reparameterization trick:\n"],"metadata":{"id":"dnQma9ZOLErV"}},{"cell_type":"markdown","source":["Reparameterization Trick:\n","$$\n","\\mathcal{N}(\\mu, \\sigma^2) = \\mu + \\sigma \\cdot \\epsilon\n","$$"],"metadata":{"id":"RLFWpVzRFnPE"}},{"cell_type":"markdown","source":["$$\n","x_t = \\sqrt{\\hat{\\alpha}_t} x_0 + \\sqrt{1 - \\hat{\\alpha}_t} \\epsilon\n","$$\n","\n","where $\\epsilon \\sim \\mathcal{N}(0, I)$ and the dimension is the same with $x$.\n"],"metadata":{"id":"THW_x7tnLSyp"}},{"cell_type":"code","source":["  # Forward diffusion process\n","  def diffuse(self, x, t, noise=None):\n","      if noise is None:\n","          noise = torch.randn_like(x)\n","      alpha_cumprod = self._alpha_cumprod(t).view(t.size(0), *[1 for _ in x.shape[1:]])\n","      return alpha_cumprod.sqrt() * x + (1 - alpha_cumprod).sqrt() * noise, noise"],"metadata":{"id":"ZbC4QXH5K8Ib"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Reverse diffusion process\n","The denoising process is the opposite of the noise addition process. A noise sample is sampled from the standard normal distribution and then gradually denoised to obtain a sample in the data distribution. As the reverse of the forward process $q(x_{t-1} | x_t)$ is intractable, DDPM learns parameterized Gaussian transitions $p_\\theta(x_{t-1} | x_t)$. Therefore, in the denoising process, the neural network predicts the parameters of the Gaussian distribution with learned mean $\\mu_\\theta$ and fixed variance $\\beta_t I$.\n","\n","$$\n","p_\\theta(x_{t-1} | x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t, t), \\beta_t I)\n","$$"],"metadata":{"id":"JoSMncXwEu2Z"}},{"cell_type":"markdown","source":["$$\n","x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{1-\\alpha_t}{\\sqrt{1-\\hat\\alpha_t}} \\epsilon \\theta(x_t, t) \\right) + \\sqrt{\\beta_t} \\mathcal{Z}\n","$$"],"metadata":{"id":"hSd_n4IBDyWb"}},{"cell_type":"code","source":["class DDPMSampler(SimpleSampler):\n","    def step(self, x, t, t_prev, noise):\n","        alpha_cumprod = self.diffuzz._alpha_cumprod(t).view(t.size(0), *[1 for _ in x.shape[1:]])\n","        alpha_cumprod_prev = self.diffuzz._alpha_cumprod(t_prev).view(t_prev.size(0), *[1 for _ in x.shape[1:]])\n","        alpha = (alpha_cumprod / alpha_cumprod_prev)\n","\n","        mu = (1.0 / alpha).sqrt() * (x - (1 - alpha) * noise / (1 - alpha_cumprod).sqrt())\n","        std = ((1 - alpha) * (1. - alpha_cumprod_prev) / (1. - alpha_cumprod)).sqrt() * torch.randn_like(mu)\n","        return mu + std * (t_prev != 0).float().view(t_prev.size(0), *[1 for _ in x.shape[1:]])"],"metadata":{"id":"K5XKVLG5welN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Sampling process\n"],"metadata":{"id":"YBpnIN5ML9j2"}},{"cell_type":"markdown","source":["<img src='https://drive.google.com/uc?id=1BtdAwtwvJaYAUgvpLxybom0Ok3ZzM2pv' width=\"1000\"/>"],"metadata":{"id":"PZzXV7NF66tj"}},{"cell_type":"code","source":["  # Sampling from the diffusion model\n","  def sample(self, model, background, shape, mask=None, t_start=1.0, t_end=0.0, timesteps=300, x_init=None, sampler='ddpm'):\n","      r_range = torch.linspace(t_start, t_end, timesteps + 1)[:, None].expand(-1, shape[0] if x_init is None else x_init.size(0)).to(self.device)\n","      if isinstance(sampler, str):\n","          if sampler in sampler_dict:\n","              sampler = sampler_dict[sampler](self)\n","          else:\n","              raise ValueError(\n","                  f\"If sampler is a string it must be one of the supported samplers: {list(sampler_dict.keys())}\")\n","      elif issubclass(sampler, SimpleSampler):\n","          sampler = sampler(self)\n","      else:\n","          raise ValueError(\"Sampler should be either a string or a SimpleSampler object.\")\n","      preds = []\n","      x = sampler.init_x(shape)\n","\n","      # Iterate over timesteps and apply diffusion model\n","      for i in tqdm(range(0, timesteps), desc=\"Sampling Progress\"):\n","          if mask is not None:\n","              x_renoised, _ = self.diffuse(x_init, r_range[i])\n","              x = x * mask + x_renoised * (1 - mask)\n","\n","          pred_noise = model(torch.cat((x, background), dim=1), r_range[i])\n","          x = self.undiffuse(x, r_range[i], r_range[i + 1], pred_noise, sampler=sampler)\n","          preds.append(x)\n","      return preds"],"metadata":{"id":"sjQFYoDULqGZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["References\n","\n","https://jalammar.github.io/illustrated-stable-diffusion/\n","\n","https://github.com/dome272/Diffusion-Models-pytorch/tree/main"],"metadata":{"id":"Bli5noeL0AWi"}}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}